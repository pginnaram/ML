{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2\n",
    "## Experiment 3\n",
    "### Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After completing this exercise please complete the Check For Understanding questions in the LMS*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "In this experiment, we will use the CIFAR-10 dataset consists of 60,000 32x32 colour images in 10 classes, with 6000 images per class. There are 50,000 training images and 10,000 test images.\n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images have been downloaded and unzipped for you in the directory cifar-10\n",
    "\n",
    "They are in a particular python-specific format called pickle. You need not worry about the format's internals, as the site has given the code needed to read such files. The code is given in the first code block below.\n",
    "\n",
    "**The code returns the contents of each data file as a dictionary**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the data\n",
    "\n",
    "There are 8 files in the cifar-10 directory.\n",
    "\n",
    "batches.meta\n",
    "\n",
    "data_batch_1\n",
    "\n",
    "data_batch_2\t\n",
    "\n",
    "data_batch_3\n",
    "\n",
    "data_batch_4\t\n",
    "\n",
    "data_batch_5\n",
    "\n",
    "readme.html\n",
    "\n",
    "test_batch\n",
    "\n",
    "We will take a peek at these files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo,encoding='bytes')\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(unpickle(\"cifar-10/data_batch_1\").keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data** a 10,000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
    "\n",
    "**labels** a list of 10,000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpickle(\"cifar-10/data_batch_1\")[b'filenames'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpickle(\"cifar-10/data_batch_1\")[b'labels'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpickle(\"cifar-10/data_batch_1\")[b'data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'data', b'batch_label', b'labels', b'filenames']\n",
      "4 10000 (10000, 3072)\n"
     ]
    }
   ],
   "source": [
    "test_data = unpickle(\"../Datasets/cifar-10/test_batch\")\n",
    "print(list(test_data.keys())) \n",
    "print(len(test_data), len(test_data[b'labels']), test_data[b'data'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data[b'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unpickle(\"cifar-10/batches.meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task\n",
    "Given a query image drawn from the test set, we attempt to find top “relevant” images from the training set\n",
    "using the K-Nearest Neighbour Method we learned earlier. \n",
    "\n",
    "The algorithm is simple, we rank the images present in the training set by their distances from the given query image. ***A\n",
    "retrieved image is considered “relevant” if the class of retrieved image is same as the query\n",
    "image.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading image features\n",
    "\n",
    "We can use the 3072 pixels as columns of data and find the distance between two 3072 dimension-space points. \n",
    "\n",
    "However that is often not the best way from effectiveness or computational efficiency. For example, instead of merely looking at the individual pixels in an image, we may find it more useful to figure out whether both images contain similar colors or similar shapes. The transformation or extraction of such higher order information is what is termed as *Feature Extraction*. This has been done for you for the cifar-10 images.\n",
    "\n",
    "The images have been converted to relevant 512 features and saved in the file \"cifar-10/cifar10features.mat\". Let us load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the features of images\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "features = sio.loadmat('cifar-10/cifar10features.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = features['x_train']\n",
    "train_labels = np.transpose(features['y_train'])\n",
    "test_features = features['x_test']\n",
    "test_labels = np.transpose(features['y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_features.shape, train_labels.shape, test_features.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN:\n",
    "\n",
    "Remember the kNN code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "\n",
    "def dist(a, b):\n",
    "    sqSum = 0\n",
    "    for i in range(len(a)):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return math.sqrt(sqSum)\n",
    "\n",
    "def kNN(k, train_feats, train_labels, given):\n",
    "    distances = []\n",
    "    for i, t in enumerate(train_feats):\n",
    "        distances.append( (dist(t, given), np.asscalar(train_labels[i])) )\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "    distances.sort()\n",
    "    return distances[:k]\n",
    "\n",
    "def kNN_classify(k, train_feats, train_labels, given):\n",
    "    tally = collections.Counter()\n",
    "    top_k = kNN(k, train_feats, train_labels, given)\n",
    "    for nn in top_k:\n",
    "        tally.update(nn[-1])\n",
    "    return tally.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall be using the kNN function. Using this function on the full train set, and an image from the test set as \"given\", we shall obtain the sorted distances of the training samples from the given test sample, along with their labels. This is **retrieval**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Excercise 0** :: Retrieve the (sorted) closest 6000 labels for test sample #10 and calcuate the precision for this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Hint: We used the KNN function only. You don't need the KNN_classify function. (Why?)\n",
    "k = 6000\n",
    "actual_class = np.asscalar(test_labels[10])\n",
    "l = kNN(k, train_features, train_labels, test_features[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Hint: Recall the definition of relevance and use it to calculate precision and recall\n",
    "### Hint: Number of relevant images is equal to the number of images of that class in the training set \n",
    "### Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, the top samples (the best 10, or best 100...) must have the same label as the given test sample. But this is not always true. To check how good the retrieval performed, we shall look at metrics such as precision@k and recall@k, in addition to accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**  :: Do you think accuracy is a valid metric to evaluate our search engine performance?\n",
    "If Yes, Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information Retrieval experts usually use two very closely related metrics called Precision@k and Recall@k to evaluate their search engine models where k corresponds to the top-k retrievals. Let’s say q is the query, U is number of images in the training set, R is the set of “relevant” images in the training set and T (k) is the retrieved set\n",
    "of images from our algorithm.\n",
    "\n",
    "                $p@k = |T(k) ∩ R|/ |T (k)|$\n",
    "                \n",
    "                $$ r@k = |T (k) ∩ R| / |R| $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**  :: Compute the precision@k and recall@k for k = 10, 100, 500, 1000, 2000, 3000, 4000, 5000, 5500, 6000. (see this and difference from earlier precision here)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**  ::  Plot the Precision-Recall Curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4**  ::  Does precision increase or decrease as we increase k, what do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**  ::  Is there a way to make recall@k = 1 for every query for some k? What is that value of k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**  ::  For real search engines, is finding recall@k feasible? Why or Why not? Is finding precision@k feasible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7** :: Do you think the feature transformation is good? Try the same set of experiments with the image pixels (converting 32 x 32 image into 3072 x 1 vector that is) directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

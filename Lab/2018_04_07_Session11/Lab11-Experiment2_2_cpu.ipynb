{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab11-Experiment2_2_cpu.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"}},"cells":[{"metadata":{"id":"4-ExfytTTldS","colab_type":"text"},"cell_type":"markdown","source":["# Foundations Of AIML\n","## Session 11\n","### Experiment 2.1: Fine-tuning pre-trained CNN"]},{"metadata":{"id":"Qi2gYJrTTldT","colab_type":"text"},"cell_type":"markdown","source":["We have seen using the pre-trained model as a black box for feature extraction. This gave us a decent accuracy. However, if we have sufficent data we can *tweak* the learned model to extract features specific to our new dataset. Note that, we have 5000 training images which is not sufficient to train a deep model from scratch. But, 5000 might be enough to *tweak* the pre-trained model to be specific to our dataset. We will see what happens when we tweak only a small specific part of the pre-trained model. We will also see how to tweak the entire model. How many layers to tweak depends on amount of available data. Finetuning to specific data, when done properly, is almost always beneficial."]},{"metadata":{"id":"RWsKSlNE9Ews","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# http://pytorch.org/\n","from os import path\n","from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n","platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n","\n","accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n","\n","!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.3.0.post4-{platform}-linux_x86_64.whl torchvision\n","import torch"],"execution_count":0,"outputs":[]},{"metadata":{"id":"b1_04297zlR0","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"b6f18da3-8eaf-45b1-b05b-d23493a9fba7","executionInfo":{"status":"ok","timestamp":1523944876809,"user_tz":-330,"elapsed":1829,"user":{"displayName":"Raghava kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"109189842157285779813"}}},"cell_type":"code","source":["%"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34mdatalab\u001b[0m/\r\n"],"name":"stdout"}]},{"metadata":{"id":"TZ2JcGuY9IjE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":175},"outputId":"655e8532-0821-4621-e5fa-40c870277766"},"cell_type":"code","source":["# The below are wrapper functions used to connect to your drive and this needs to be run once (i.e. once every new session or possibily refreshes for every 24 hours)\n","\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","# Authentication for your google drive\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","\n","# Authentication for the wrapper libraries  or possibily refreshes for every 24 hours)\n","\n","!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","\n","\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","\n","# Create a directory and mount Google Drive using that directory.\n","!mkdir -p MyDrive\n","!google-drive-ocamlfuse MyDrive\n","\n","%cd MyDrive/Session-11-Experiments"],"execution_count":0,"outputs":[{"output_type":"stream","text":["gpg: keybox '/tmp/tmpjybi_173/pubring.gpg' created\n","gpg: /tmp/tmpjybi_173/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n"],"name":"stdout"}]},{"metadata":{"id":"Vz6KHAhU9X12","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Importing pytorch packages\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","# Importing config.py file\n","import config as cf\n","from utils import *\n","from light_cnn import network_9layers\n","from data_loader import *\n","## Importing python packages\n","import cv2\n","import os\n","import sys\n","import time\n","import datetime\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Ivz2EdflTldX","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"6e037f5f-f2bc-433a-deb2-a72de859424d","executionInfo":{"status":"ok","timestamp":1523944658643,"user_tz":-330,"elapsed":1548,"user":{"displayName":"Raghava kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"109189842157285779813"}}},"cell_type":"code","source":["img_root = cf.data_dir+'IMFDB_final/'\n","\n","train_list_file = cf.data_dir+'IMFDB_train.txt'   #### 5000 images for training\n","val_list_file = cf.data_dir+'IMFDB_test.txt'      #### 1095 images for validation\n","\n","\n","train_image_list = [line.rstrip('\\n') for line in open(train_list_file)]\n","val_image_list = [line.rstrip('\\n') for line in open(val_list_file)]\n","\n","print(len(train_image_list), len(val_image_list))\n","\n","trainloader = torch.utils.data.DataLoader(custom_data_loader(img_root = img_root, image_list = train_list_file, crop=False,\n","                                                             resize = True, resize_shape=[128,128]), \n","                                           batch_size=32, num_workers=16, shuffle = True, pin_memory=False)\n","\n","testloader = torch.utils.data.DataLoader(custom_data_loader(img_root = img_root, image_list = val_list_file, crop=False, mirror=False, \n","                                                           resize = True, resize_shape=[128,128]), \n","                                           batch_size=10, num_workers=5, shuffle = False, pin_memory=False)\n","\n","\n","classes = ['AamairKhan', 'Rimisen', 'Kajol', 'KareenaKapoor','RishiKapoor', 'AmrishPuri', 'AnilKapoor', 'AnupamKher', 'BomanIrani', 'HrithikRoshan', 'KajalAgarwal', 'KatrinaKaif', 'Madhavan', 'MadhuriDixit', 'Umashri', 'Trisha']"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(5000, 1095)\n"],"name":"stdout"}]},{"metadata":{"id":"P8RLERw1Tldb","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# Checking for GPU instance\n","use_cuda = torch.cuda.is_available()\n","#Intilizaing the accuracy value as zero\n","best_acc = 0\n","num_classes = 16"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aIka81ZjTldd","colab_type":"text"},"cell_type":"markdown","source":["### Net surgery\n","the original pre-trained model has the last layer (fc2) for 79077 classes but we want to have last layer for only 16 classes.\n","We chop-off the fc2 with 79077 classes and *implant* a new classifier (the MLP model we used in the previous experiment) which predicts 16 classes. Note that we could also implant a single FC layer with 16 classes (instead of a 3 layer MLP)."]},{"metadata":{"id":"x9D5SoK2Tlde","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["feature_net = network_9layers()   ### creates an object of this network architecture\n","feature_net = torch.load(cf.data_dir+'light_cnn/light_cnn_ckpt.t7')['net']\n","\n","### starting the surgery\n","layers_to_remove = ['fc2']\n","for layers_ in layers_to_remove:        \n","    del(feature_net._modules[layers_])\n","    \n","#### old fc2 removed.\n","\n","classifier = nn.Sequential(nn.Linear(256, 64), nn.BatchNorm1d(64), nn.ReLU(),\n","                           nn.Linear(64, 32), nn.BatchNorm1d(32), nn.ReLU(),\n","                           nn.Linear(32, num_classes))\n","\n","### implanting a new fc2\n","feature_net.fc2 = classifier\n","if use_cuda:\n","    feature_net.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ixaB0JXpTldg","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["### Intiliazing the loss\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YJfaPth3Tldi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def train(epoch):\n","    print('\\nEpoch: %d' % epoch)\n","    feature_net.train()\n","    train_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(trainloader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        optimizer.zero_grad()\n","        inputs, targets = Variable(inputs), Variable(targets)\n","        outputs = feature_net(inputs)      ### notice that the pre-trained network has an implant classifier which directly outputs the 16 class prediction scores\n","\n","        \n","        size_ = outputs.size()\n","        outputs_ = outputs.view(size_[0], num_classes)\n","        loss = criterion(outputs_, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.data[0]\n","        _, predicted = torch.max(outputs_.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","        \n","        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","        \n","    train_loss_file.write('%d %.3f %.3f\\n' %(epoch, train_loss/len(trainloader), 100.*correct/total))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"doi3xspHTldk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def test(epoch):\n","    global best_acc\n","    feature_net.eval()\n","    test_loss = 0\n","    correct = 0\n","    total = 0\n","    for batch_idx, (inputs, targets) in enumerate(testloader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n","        outputs = feature_net(inputs)\n","        size_ = outputs.size()\n","        outputs_ = outputs.view(size_[0], num_classes)\n","        loss = criterion(outputs_, targets)\n","\n","        test_loss += loss.data[0]\n","        _, predicted = torch.max(outputs_.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","        \n","        progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n","                         % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n","        \n","    val_loss_file.write('%d %.3f %.3f\\n' %(epoch,  test_loss/len(testloader), 100.*correct/total))\n","\n","    # Save checkpoint.\n","    acc = 100.*correct/total\n","    if acc > best_acc:\n","        print('Saving..')\n","        state = {\n","            'net': classifier,\n","            'acc': acc,\n","            'epoch': epoch,\n","        }\n","        if not os.path.isdir(cf.data_dir+'checkpoint'):\n","            os.mkdir(cf.data_dir+'checkpoint')\n","        torch.save(state, cf.data_dir+'checkpoint/checkpoint_ckpt.t7')\n","        best_acc = acc\n","    \n","    return test_loss/len(testloader)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0klsnhXITldm","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["experiment = 'lightnet_finetune_fc1_fc2_IMFDB'\n","train_loss_file = open(cf.data_dir+experiment+\"train_loss.txt\", \"w\", 0)\n","val_loss_file = open(cf.data_dir+experiment+\"val_loss.txt\", \"w\", 0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9s-d83ALTldp","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":1309},"outputId":"b0647768-52a5-4a45-be0f-10287eaf778d"},"cell_type":"code","source":["### tweak only selected parts : FC1 and FC2. FC2 is 3 layer MLP.\n","\n","layers_to_finetune = [{'params': feature_net.fc1.parameters()},\n","                      {'params':feature_net.fc2.parameters()}]\n","\n","optimizer = optim.Adam(layers_to_finetune, lr=0.001)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)   #### dynamic LR scheduler\n","for epoch in range(0, 30):\n","    train(epoch)\n","    test_loss = test(epoch)\n","    scheduler.step(test_loss)\n","    \n","train_loss_file.close()\n","val_loss_file.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Epoch: 0\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","ERROR: couldn't find image ->  isfile data/IMFDB_final/KajalAgarwal/Misc/images/KajolAggarwal_133.jpg\n","ERROR: couldn't find image -> image_is_none data/IMFDB_final/KajalAgarwal/Misc/images/KajolAggarwal_133.jpg\n","creating a default image\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","ERROR: couldn't find image ->  isfile data/IMFDB_final/Madhavan/MydearMunnabhai/images/Madhavan_98.jpg\n","ERROR: couldn't find image -> image_is_none data/IMFDB_final/Madhavan/MydearMunnabhai/images/Madhavan_98.jpg\n","image not none resizing\n","creating a default image\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n","image not none resizing\n"],"name":"stdout"}]},{"metadata":{"id":"sgJO1gL_Tldr","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":164},"outputId":"1fe1bf10-8b54-4905-9861-58082fbe4d09","executionInfo":{"status":"error","timestamp":1523944864443,"user_tz":-330,"elapsed":1111,"user":{"displayName":"Raghava kumar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"109189842157285779813"}}},"cell_type":"code","source":["training_curves(cf.data_dir+experiment)"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m\u001b[0m","\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)","\u001b[0;32m<ipython-input-1-bb4b283aafa7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'training_curves' is not defined"]}]},{"metadata":{"id":"cDzxX7rDTldu","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["### After training we load the model that performed the best on validation data (avoid picking overfitted model)\n","classifier = torch.load(cf.data_dir+'checkpoint/checkpoint_ckpt.t7')['net'].eval()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FwYoE2fCTldw","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["def eval():\n","    feature_net.eval()\n","    \n","    testloader = torch.utils.data.DataLoader(custom_data_loader(img_root = img_root, image_list = val_list_file, crop=False, mirror=False, \n","                                                           resize = True, resize_shape=[128,128]), \n","                                           batch_size=1, num_workers=1, shuffle = False, pin_memory=True)\n","    correct = 0\n","    total = 0\n","    conf_mat = np.zeros((num_classes, num_classes))\n","    total_ = np.zeros((num_classes))\n","    wrong_predictions = []\n","    for batch_idx, (inputs, targets) in enumerate(testloader):\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        inputs, targets = Variable(inputs, volatile=True), Variable(targets)\n","        outputs = feature_net(inputs)\n","        size_ = outputs.size()\n","        outputs_ = outputs.view(size_[0], num_classes)\n","        _, predicted = torch.max(outputs_.data, 1)\n","        total += targets.size(0)\n","        correct += predicted.eq(targets.data).cpu().sum()\n","        prediction = predicted.cpu().numpy()[0]\n","        targets = targets.data.cpu().numpy()[0]\n","        total_[targets] +=1\n","        conf_mat[predicted, targets] +=1\n","        \n","        if prediction != targets:\n","            wrong_predictions += [[inputs, prediction, targets]]\n","        \n","    for k in range(num_classes):\n","        conf_mat[:,k] /= total_[k]\n","    return conf_mat, 100.*correct/total, wrong_predictions\n","    "],"execution_count":0,"outputs":[]},{"metadata":{"id":"UBwuYGC5Tld1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["conf, acc, wrong_predictions = eval()\n","print('Accuracy:', acc, '%')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bJ-5lHnhTld4","colab_type":"text"},"cell_type":"markdown","source":["Whoa!! :o Fine-tuning improved the accuracy by more than 15%"]},{"metadata":{"id":"-y7lc6FwTld5","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["plt.imshow(conf, cmap='jet', vmin=0, vmax = 1)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6waQqQ3TTld8","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["for w in wrong_predictions[::10]:\n","    print classes[w[2]], 'confused with', classes[w[1]]\n","    plt.imshow(w[0][0][0].data.cpu().numpy(), cmap='gray')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dkiFsCk4Tld_","colab_type":"text"},"cell_type":"markdown","source":["### Now let's try fine-tuning all layers in the network"]},{"metadata":{"id":"7GTnIHtoTleA","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["feature_net = network_9layers()   ### creates an object of this network architecture\n","feature_net = torch.load(cf.data_dir+'light_cnn/light_cnn_ckpt.t7')['net']\n","\n","layers_to_remove = ['fc2']\n","for layers_ in layers_to_remove:        \n","    del(feature_net._modules[layers_])\n","    \n","\n","\n","classifier = nn.Sequential(nn.Linear(256, 64), nn.BatchNorm1d(64), nn.ReLU(),\n","                           nn.Linear(64, 32), nn.BatchNorm1d(32), nn.ReLU(),\n","                           nn.Linear(32, num_classes))\n","\n","feature_net.fc2 = classifier\n","if use_cuda:\n","    feature_net.cuda()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9tlfACXMTleE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["layers_to_finetune = [{'params': feature_net.features.parameters()}, \n","                      {'params': feature_net.fc1.parameters()},\n","                      {'params':feature_net.fc2.parameters()}]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RalOGTOMTleH","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["experiment = 'lightnet_finetune_all_IMFDB'\n","train_loss_file = open(cf.data_dir+experiment+\"train_loss.txt\", \"w\", 0)\n","val_loss_file = open(cf.data_dir+experiment+\"val_loss.txt\", \"w\", 0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PhSRpwQfTleJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["best_acc = 0\n","optimizer = optim.Adam(layers_to_finetune, lr=0.001)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=2, verbose=True)   #### dynamic LR scheduler\n","for epoch in range(0, 30):\n","    train(epoch)\n","    test_loss = test(epoch)\n","    scheduler.step(test_loss)\n","    \n","train_loss_file.close()\n","val_loss_file.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"d-5HIIK2TleL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["training_curves(cf.data_dir+experiment)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GJb_mdMcTleN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["classifier = torch.load(cf.data_dir+'checkpoint/checkpoint_ckpt.t7')['net'].eval()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OKAxg2N2TleO","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["conf, acc, wrong_predictions = eval()\n","print('Accuracy:', acc, '%')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1l5s22yNTleQ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["plt.imshow(conf, cmap='jet', vmin=0, vmax = 1)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"476W06wFTleR","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["for w in wrong_predictions[::10]:\n","    print(classes[w[2]], 'confused with', classes[w[1]])\n","    plt.imshow(w[0][0][0].data.cpu().numpy(), cmap='gray')\n","    plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NXyw6zO-TleT","colab_type":"text"},"cell_type":"markdown","source":["Relying on pre-trained networks we improved the accuracy by more than 20%!!"]},{"metadata":{"id":"v-_3EyftTleT","colab_type":"text"},"cell_type":"markdown","source":["### Different parts of the model can have different LR. While fine-tuning it is common to set the implanted layers to 10 times higher LR than pre-trained layers. This helps the implanted layers learns faster since it is starting from scratch."]},{"metadata":{"id":"LkOXGdshTleU","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of AI & ML\n",
    "## Session 07\n",
    "### CaseStudy 1\n",
    "### Lab\n",
    "\n",
    "**Objectives:** Create a non-linear regression based product rating solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"../Datasets/amazon_reviews.csv\")\n",
    "print(data.describe())\n",
    "data = data.dropna()\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I like the item pricing. My granddaughter want...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Love the magnet easel... great for moving to d...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Both sides are magnetic.  A real plus when you...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bought one a few years ago for my daughter and...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I have a stainless steel refrigerator therefor...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            reviews  ratings\n",
       "0           0  I like the item pricing. My granddaughter want...      5.0\n",
       "1           1  Love the magnet easel... great for moving to d...      4.0\n",
       "2           2  Both sides are magnetic.  A real plus when you...      5.0\n",
       "3           3  Bought one a few years ago for my daughter and...      5.0\n",
       "4           4  I have a stainless steel refrigerator therefor...      4.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167592</th>\n",
       "      <td>167592</td>\n",
       "      <td>This drone is very fun and super duarable. Its...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167593</th>\n",
       "      <td>167593</td>\n",
       "      <td>This is my brother's most prized toy. It's ext...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167594</th>\n",
       "      <td>167594</td>\n",
       "      <td>This Panther Drone toy is awesome. I definitel...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167595</th>\n",
       "      <td>167595</td>\n",
       "      <td>This is my first drone and it has proven to be...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167596</th>\n",
       "      <td>167596</td>\n",
       "      <td>This is a super fun toy to have around. In our...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                            reviews  ratings\n",
       "167592      167592  This drone is very fun and super duarable. Its...      5.0\n",
       "167593      167593  This is my brother's most prized toy. It's ext...      5.0\n",
       "167594      167594  This Panther Drone toy is awesome. I definitel...      5.0\n",
       "167595      167595  This is my first drone and it has proven to be...      5.0\n",
       "167596      167596  This is a super fun toy to have around. In our...      4.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = data['ratings'].values\n",
    "reviews = data['reviews'].values\n",
    "lengths = [len(r) for r in reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We first preprocess the data by removing all the incorrect rows (that have missing rating or reviews), unwanted columns, removing stopwords and soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "only_alnum = re.compile(r\"[^a-z0-9]+\")\n",
    "## Replaces one or more occurrence of any characters other than a-z and 0-9 with a space\n",
    "## This automatically replaces multiple spaces by 1 space\n",
    "\n",
    "## The try ... except ensures that if a review is mal-formed then the review is replaced with the word ERROR\n",
    "def cleanUp(s):\n",
    "    return re.sub(only_alnum, \" \", s.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We make a set for testing if a word is not useful\n",
    "## sets are way faster than lists for this purpose\n",
    "fluff = set([w.strip() for w in open(\"../Datasets/fluff.txt\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool\n",
      "amaazzing\n",
      "cool\n"
     ]
    }
   ],
   "source": [
    "## Replace words like coooooool with cool, amaaaaaazing with amaazing and so on\n",
    "def dedup(s):\n",
    "    return re.sub(r'([a-z])\\1+', r'\\1\\1', s)\n",
    "print(dedup(\"cooooool\"))\n",
    "print(dedup(\"amaaaaaazzzzing\"))\n",
    "print(dedup('cool'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_useful_words(s):\n",
    "    return [dedup(w) for w in cleanUp(s).split() if len(w) > 2 and w not in fluff]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100 I like the item pricing. My granddaughter wanted to mark on it but I wanted it just for the letters. \n",
      "==> ['like', 'item', 'pricing', 'granddaughter', 'mark', 'letters']\n",
      " 121 Love the magnet easel... great for moving to different areas... Wish it had some sort of non skid pad on bottom though... \n",
      "==> ['love', 'magnet', 'easel', 'great', 'moving', 'wish', 'sort', 'skid', 'pad', 'bottom']\n",
      " 420 Both sides are magnetic.  A real plus when you're entertaining more than one child.  The four-year old can find the letters for the words, while the two-year old can find the pictures the words spell.  (I bought letters and magnetic pictures to go with this board).  Both grandkids liked it a lot, which means I like it a lot as well.  Have not even introduced markers, as this will be used strictly as a magnetic board. \n",
      "==> ['magnetic', 'real', 'plus', 'entertaining', 'more', 'child', 'letters', 'words', 'pictures', 'words', 'spell', 'bought', 'letters', 'magnetic', 'pictures', 'board', 'grandkids', 'liked', 'lot', 'means', 'like', 'lot', 'introduced', 'markers', 'strictly', 'magnetic', 'board']\n",
      " 149 Bought one a few years ago for my daughter and she loves it, still using it today. For the holidays we bought one for our niece and she loved it too. \n",
      "==> ['bought', 'few', 'ago', 'daughter', 'loves', 'using', 'holidays', 'bought', 'niece', 'loved']\n",
      " 244 I have a stainless steel refrigerator therefore there are not much space for my son to play with his magnet. Brought this for him to put his magnet on. He enjoys sticking his magnet on it. Great to have so he can play with his alphabet magnets. \n",
      "==> ['stainless', 'steel', 'refrigerator', 'space', 'son', 'play', 'magnet', 'brought', 'magnet', 'enjoys', 'sticking', 'magnet', 'great', 'play', 'alphabet', 'magnets']\n"
     ]
    }
   ],
   "source": [
    "clean_reviews = [get_useful_words(review) for review in reviews]\n",
    "for i in range(5):\n",
    "    print(\"%4d\" %(len(reviews[i])), reviews[i], \"\\n==>\", clean_reviews[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reviews = list(zip(clean_reviews, ratings, lengths))\n",
    "#We look at a Random sample of 10 cleaned data.\n",
    "import random\n",
    "for i in range(10):\n",
    "    r = random.randrange(0, len(final_reviews))\n",
    "    print(final_reviews[r])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Case-Study:** Use the list of substantive words extracted from the Review as well as the length of the original Review. Decide how you would like to Derive a feature set to predict the Rating, which is a float (1.0 to 5.0).\n",
    "\n",
    "Remember to split the Data into training, testing and Validation sets.\n",
    "1. Select 10% of the Data for testing and put it away.\n",
    "2. Select 20% of the Data for Validation and 70% for Training.\n",
    "3. Vary the above ratio between Validation and Testing: 30 - 60, 45 - 45, 60 - 30 and Verify the effect if any on the prediction accuracy.\n",
    "\n",
    "\n",
    "Some Possibilities:\n",
    "\n",
    "1. You can use a single feature namely, the difference between number of Positive & Negative words. \n",
    "\n",
    "2. You can also considering predicting the rating based on the above difference and add the length of the Review as two independent Variables.\n",
    "\n",
    "3. You could consider the Positive Words and Negative Words as two independent Variables rather than treating their difference as single independent Variable, giving you more possibilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training, validation and test data ( 70, 20 ,10)\n",
    "def split_data(final_reviews, train, val, test):\n",
    "    total_len = len(final_reviews)\n",
    "    train_coll = [i for i in final_reviews[:int(train * total_len)]]\n",
    "    val_coll = [i for i in final_reviews[int(train * total_len): int((train+val) * total_len)]]\n",
    "    test_coll = [i for i in final_reviews[int((train+val) * total_len):] ]\n",
    "    \n",
    "    return(train_coll, val_coll, test_coll)\n",
    "\n",
    "(train_coll, val_coll, test_coll) = split_data(final_reviews, 0.7, 0.2, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = pd.read_csv(\"Datasets/positive-words.txt\")\n",
    "negative_words = pd.read_csv(\"Datasets/negative-words.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, data of amazon ratings file consists of three columns called set,labels and length part. here we are splitting the three columns and making three different lists as set, labels and len_Set respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for training data\n",
    "train_set = [i[0] for i in train_coll]\n",
    "val_set =   [i[0] for i in val_coll]\n",
    "test_set =  [i[0] for i in test_coll]\n",
    "\n",
    "#for validation data\n",
    "train_labels = [i[1] for i in train_coll]\n",
    "val_labels = [i[1] for i in val_coll]\n",
    "test_labels = [i[1] for i in test_coll]\n",
    "\n",
    "#for testing data\n",
    "train_len_set = [i[2] for i in train_coll]\n",
    "val_len_set = [i[2] for i in val_coll]\n",
    "test_len_set = [i[2] for i in test_coll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=[] #features list for training data\n",
    "val_features=[] #features list for validation data\n",
    "test_features=[] #features list for testing data\n",
    "pos_train=[] #postive words count list for training data\n",
    "neg_train=[] #negative words count list for training data\n",
    "pos_val=[] #positve words count list for validation data\n",
    "neg_val=[] #negative words count list for validation data\n",
    "pos_test=[] #positve words count list for testing data\n",
    "neg_test=[] #negative words count list for testing data\n",
    "\n",
    "for i in range(len(train_set)):\n",
    "    pos=0\n",
    "    neg=0\n",
    "    for j in range(len(train_set[i])):\n",
    "        if train_set[i][j] in positive_words.values:\n",
    "            pos+=1\n",
    "        elif train_set[i][j] in negative_words.values:\n",
    "            neg+=1\n",
    "    pos_train.append(pos)\n",
    "    neg_train.append(pos)\n",
    "    train_features.append(abs(pos-neg))\n",
    "for i in range(len(val_set)):\n",
    "    pos=0\n",
    "    neg=0\n",
    "    for j in range(len(val_set[i])):\n",
    "        if val_set[i][j] in positive_words.values:\n",
    "            pos+=1\n",
    "        elif val_set[i][j] in negative_words.values:\n",
    "            neg+=1\n",
    "    pos_val.append(pos)\n",
    "    neg_val.append(neg)\n",
    "    val_features.append(abs(pos-neg))\n",
    "for i in range(len(test_set)):\n",
    "    pos=0\n",
    "    neg=0\n",
    "    for j in range(len(test_set[i])):\n",
    "        if test_set[i][j] in positive_words.values:\n",
    "            pos+=1\n",
    "        elif test_set[i][j] in negative_words.values:\n",
    "            neg+=1\n",
    "    pos_test.append(pos)\n",
    "    neg_val.append(neg)\n",
    "    test_features.append(abs(pos-neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, c, _, _, _ = ss.linregress(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(m)\n",
    "print(c)\n",
    "print(\"m = {0:.6} c = {1:.6} \".format(m, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_features), len(train_labels), len(test_len_set))\n",
    "yt = [ m * i + c  for i in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "print(\"m = {0:.6} c = {1:.6} \".format(m, c))\n",
    "yt = [ m * i + c  for i in test_features]\n",
    "\n",
    "ax.clear()\n",
    "ax.plot(test_features, test_labels, '.k')\n",
    "ax.plot(test_features, yt)\n",
    "fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positive -neagtive count + total number of words\n",
    "train_features_2 = [] #features list for training data\n",
    "val_features_2 =[] #features list for validation data\n",
    "test_features_2 =[] #features list for testing data\n",
    "for i in range(len(train_set)):\n",
    "    train_features_2.append((train_features[i], train_len_set[i]))\n",
    "for i in range(len(val_set)):\n",
    "    val_features_2.append((val_features[i], val_len_set[i]))\n",
    "for i in range(len(test_set)):\n",
    "    test_features_2.append((test_features[i], test_len_set[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression()\n",
    "lm.fit(train_features_2, train_labels)\n",
    "\n",
    "pred_train = lm.predict(train_features_2)\n",
    "pred_test = lm.predict(test_features_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Fit a model train_features_2, and calculate MSE with train_labels:',  np.mean((train_labels - pred_train) ** 2))\n",
    "print ('Fit a model train_features_2, and calculate MSE with test_features_1, test_labels:', np.mean((test_labels - pred_test) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred_train, pred_train-train_labels, c='b',s=40,alpha=0.5)\n",
    "plt.scatter(pred_test, pred_test-test_labels, c='g',s=40)\n",
    "plt.hlines(y=0, xmin=0, xmax=50)\n",
    "plt.title('Residual plot with training in blue and test in green')\n",
    "plt.ylabel('Residuals')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Positive, negative words and total words\n",
    "train_features_3=[] #features list for training data\n",
    "val_features_3 = [] #features list for validation data\n",
    "test_features_3 = [] #features list for testing data\n",
    "for i in range(len(train_set)):\n",
    "    train_features_3.append((pos_train[i], neg_train[i], train_len_set[i]))\n",
    "for i in range(len(val_set)):\n",
    "    val_features_3.append((pos_val[i], neg_val[i], val_len_set[i]))\n",
    "for i in range(len(test_set)):\n",
    "    test_features_3.append((pos_val[i], neg_val[i], test_len_set[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm1 = LinearRegression()\n",
    "lm1.fit(train_features_3, train_labels)\n",
    "\n",
    "pred_train_1 = lm1.predict(train_features_3)\n",
    "pred_test_1 = lm1.predict(test_features_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Fit a model train_features_3, and calculate MSE with train_labels:',  np.mean((train_labels - pred_train_1) ** 2))\n",
    "print ('Fit a model train_features_3, and calculate MSE with test_features_3, test_labels:', np.mean((test_labels - pred_test_1) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred_train_1, pred_train_1-train_labels, c='b',s=40,alpha=0.5)\n",
    "plt.scatter(pred_test_1, pred_test_1-test_labels, c='g',s=40)\n",
    "plt.hlines(y=0, xmin=0, xmax=50)\n",
    "plt.title('Residual plot with training in blue and test in green')\n",
    "plt.ylabel('Residuals')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

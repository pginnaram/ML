{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of AI & ML\n",
    "## Session 05\n",
    "### Experiment 1 - Part 3\n",
    "## \"Sequential\" Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objectives:** We will use single sample(Sequential) Gradient Descent Method in this Experiment and see the variations when each and every single point is used instead of the Batch.\n",
    "\n",
    "**Expected Time:** This Experiment should take around 15 mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stat\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../Datasets/regr01.txt\", sep=\" \", header=None, names=['l', 't'])\n",
    "#print(data.head())\n",
    "#print(data.tail()) \n",
    "#data = shuffle(data)\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = data['l'].values\n",
    "t = data['t'].values\n",
    "tsq = t * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample - Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the essenial parts of the Gradient Descent method\n",
    "using each and every single point.\n",
    "\n",
    "$y = mx + c$\n",
    "\n",
    "$E$ = $(y_i - y)^2$\n",
    "\n",
    "$\\frac{\\partial E }{\\partial m}$ = $ -(y_i - (mx_i + c)) * x_i$\n",
    "\n",
    "$\\frac{\\partial E }{\\partial c}$ = $ -(y_i - (mx_i + c))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, m, c, eta):\n",
    "    ycalc = m * x + c\n",
    "    error = (y - ycalc) ** 2\n",
    "    delta_m = -(y - ycalc) * x\n",
    "    delta_c = -(y - ycalc)\n",
    "    m = m - delta_m * eta\n",
    "    c = c - delta_c * eta\n",
    "    return m, c, error\n",
    "\n",
    "def train_per_sample(x,y,m,c,eta):\n",
    "    for x_sample, y_sample in zip(x, y):\n",
    "        m, c, e = train(x_sample, y_sample, m, c,eta)\n",
    "        #print(m,c,e)\n",
    "    return m, c, e\n",
    "\n",
    "def train_sequential(x, y, m, c, eta, iterations=1000):\n",
    "    for iteration in range(iterations):\n",
    "        m, c, err = train_per_sample(x, y, m, c, eta)\n",
    "    return m, c, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us visualize the training in this case:\n",
    "\n",
    "### $\\eta$ = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing m and c to 0\n",
    "m, c = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing learning rate\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training for 1000 iterations, plotting after every 100 iterations:\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "plt.ion()\n",
    "fig.show()\n",
    "fig.canvas.draw()\n",
    "\n",
    "for num in range(10):\n",
    "    m, c, error = train_sequential(l, tsq, m, c, lr, iterations=200)\n",
    "    print(\"m = {0:.6} c = {1:.6} Error = {2:.6}\".format(m, c, error))\n",
    "    y = m * l + c\n",
    "    ax.clear()\n",
    "    ax.plot(l, tsq, '.k')\n",
    "    ax.plot(l, y)\n",
    "    fig.canvas.draw()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Experiment with more iterations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting error vs iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms, cs,errs = [], [], []\n",
    "m, c = 0, 0\n",
    "lr = 0.001\n",
    "for times in range(100):\n",
    "    m, c, error = train_sequential(l, tsq, m, c, lr, iterations=100) # We will plot the value of for every 100 iterations\n",
    "    ms.append(m)\n",
    "    cs.append(c)\n",
    "    errs.append(error)\n",
    "epochs = range(0, 10000, 100)\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs, errs)\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Sequential Gradient Descent\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise: Is this better than vanilla gradient descent?**\n",
    "\n",
    "Hint: Check the error value at saturation, and the number of iterations it takes to reach saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Last Error at saturation: 0.007\n",
    "def find_itr(epochs,errs):\n",
    "    for i in range(len(epochs)):\n",
    "        if(errs[i] <= 0.007):\n",
    "            return epochs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_itr(epochs,errs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

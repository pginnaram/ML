{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of AI & ML\n",
    "## Session 08\n",
    "### Experiment 2\n",
    "### Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting refers to a model that models the training data too well.\n",
    "\n",
    "Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. \n",
    "\n",
    "In this experiment we are going to use 2 features from Iris Dataset to Visualise Overfitting step by step.\n",
    "  1. Plot training error and Test error\n",
    "  2. Observe when the overfitting starts in the plot.\n",
    "\n",
    "You will understand by the end of this Experiment how detail in the data negatively impacts the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading iris dataset from sklearn\n",
    "iris = datasets.load_iris()\n",
    "## Storing only 2 features \n",
    "X = iris.data[:,(0,2)]\n",
    "## Storing the target data\n",
    "Y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Exercise 1 ** Split the data into train,test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hint : you can use np.split\n",
    "X_train, X_test, X_validation = ???\n",
    "Y_train, Y_test, Y_validation = ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear function\n",
    "def linf(m, x):\n",
    "    return np.matmul(x,m)\n",
    "\n",
    "def one_step(x, y, m, eta):\n",
    "    #Predicting the values\n",
    "    ypred = linf(m, x)\n",
    "    #Calculating the error\n",
    "    error = np.linalg.norm((y - ypred)**2)\n",
    "    #calculating the delta value\n",
    "    delta_m = -2*np.matmul(x.T,(y - ypred))\n",
    "    #updating m value\n",
    "    m = m - (delta_m * eta)\n",
    "    return m, error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 ** Calculate the test error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feat = len(X_train[0]) \n",
    "#Intilizing the m value with random value\n",
    "m = np.random.uniform(-1,1,(num_feat+1,1))\n",
    "# Learning rate\n",
    "eta = 2e-4\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "#reshaping the size of Y_test array\n",
    "Y_test = np.reshape(Y_test, (Y_test.shape[0],1))\n",
    "#reshaping the size of Y_train array\n",
    "Y_train = np.reshape(Y_train, (Y_train.shape[0],1))\n",
    "## adding additional ones to X_train and X_test arrays\n",
    "X_train=np.hstack( (X_train,np.ones((X_train.shape[0],1)))) \n",
    "X_test=np.hstack( (X_test,np.ones((X_test.shape[0],1)))) \n",
    "\n",
    "for times in range(50):\n",
    "    ## Calling the function\n",
    "    m, error = one_step(X_train, Y_train, m, eta)\n",
    "    if times%1==0:\n",
    "        # appending the trained error to train_errs\n",
    "        train_errs.append(error)\n",
    "        # Calculating the test errors and appending them to test_errs\n",
    "        test_errs.append(???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plotting the train_errs and test_errs\n",
    "plt.plot(train_errs)\n",
    "plt.plot(test_errs)\n",
    "plt.legend([\"Train\",\"Test\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nMinimum Training Error occurs at {} degrees.'.format(int(np.argmin(train_errs))))\n",
    "print('Minimum Testing Error occurs at {} degrees.\\n'.format(int(np.argmin(test_errs))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 **  Vary the train ,test and validation ratios and observe how overfitting changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_validation = np.split(X, [int(.6 * len(X)), int(.8 * len(X))])\n",
    "Y_train, Y_test, Y_validation = np.split(Y, [int(.6 * len(Y)), int(.8 * len(Y))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_errs.append(np.linalg.norm((Y_test - linf(m,X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_validation = np.split(X, [int(.5 * len(X)), int(.7 * len(X))])\n",
    "Y_train, Y_test, Y_validation = np.split(Y, [int(.5 * len(Y)), int(.7 * len(Y))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
